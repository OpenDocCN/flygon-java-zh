# 第一章。第一步-并发设计原则

计算机系统的用户总是在寻求系统的更好性能。他们希望获得更高质量的视频、更好的视频游戏和更快的网络速度。几年前，处理器通过提高速度为用户提供了更好的性能。但现在，处理器不再提高速度。相反，它们增加了更多的核心，以便操作系统可以同时执行多个任务。这被称为并发。并发编程包括所有工具和技术，以便在计算机中同时运行多个任务或进程，它们之间进行通信和同步，而不会丢失数据或不一致。在本章中，我们将涵盖以下主题：

+   基本并发概念

+   并发应用中可能出现的问题

+   设计并发算法的方法论

+   Java 并发 API

+   Java 内存模型

+   并发设计模式

+   设计并发算法的技巧和窍门

# 基本并发概念

首先，让我们介绍并发的基本概念。你必须理解这些概念才能继续阅读本书的其余部分。

## 并发与并行

并发和并行是非常相似的概念。不同的作者对这些概念给出了不同的定义。最被接受的定义是，当你在单个处理器上有多个任务，并且操作系统的任务调度程序快速地从一个任务切换到另一个任务时，就会出现并发，因此似乎所有任务都在同时运行。同样的定义也提到，当你有多个任务在不同的计算机、处理器或处理器内的不同核心上同时运行时，就会出现并行。

另一个定义提到，当你的系统上有多个任务（不同的任务）同时运行时，就会出现并发。另一个定义讨论了当你在数据集的不同部分上同时运行相同任务的不同实例时，就会出现并行。

我们包含的最后一个定义提到，当你的系统中有多个任务同时运行时，就会出现并行，并且提到并发来解释程序员们用来与任务同步和访问共享资源的不同技术和机制。

正如你所看到的，这两个概念非常相似，并且随着多核处理器的发展，这种相似性已经增加。

## 同步

在并发中，我们可以将同步定义为协调两个或多个任务以获得期望的结果。我们有两种同步方式：

+   控制同步：例如，一个任务依赖于另一个任务的结束，第二个任务在第一个任务完成之前不能开始

+   数据访问同步：当两个或更多任务访问共享变量，且在任何给定时间只有一个任务可以访问该变量

与同步密切相关的一个概念是关键部分。关键部分是一段代码，因为其对共享资源的访问，只能由一个任务在任何给定时间执行。互斥是用来保证这一要求的机制，并且可以通过不同的方式实现。

请记住，同步可以帮助你避免一些并发任务可能出现的错误（它们将在本章后面描述），但它会给你的算法引入一些开销。你必须非常仔细地计算可以在并行算法中独立执行而不需要相互通信的任务数量。这就是你并发算法的**粒度**。如果你有**粗粒度的粒度**（大任务低相互通信），同步的开销会很低。然而，也许你无法充分利用系统的所有核心。如果你有**细粒度的粒度**（高相互通信的小任务），同步的开销会很高，也许你的算法的吞吐量不会很好。

在并发系统中有不同的机制来实现同步。从理论上讲，最流行的机制有：

+   **信号量**：信号量是一种可以用来控制对一个或多个资源单元的访问的机制。它有一个变量来存储可以使用的资源数量，以及两个原子操作来管理变量的值。**互斥锁**（**mutual exclusion**的缩写）是一种特殊类型的信号量，它只能取两个值（*资源空闲*和*资源忙碌*），只有设置互斥锁为*忙碌*的进程才能释放它。

+   **监视器**：监视器是一种获得共享资源的互斥的机制。它有一个互斥锁、一个条件变量和两个等待条件和信号条件的操作。一旦你发出条件，只有一个等待它的任务可以继续执行。

与同步相关的最后一个概念是**线程安全**。如果所有共享数据的用户都受到同步机制的保护，非阻塞的**比较和交换**（**CAS**）原语或数据是不可变的，那么一段代码（或一个方法或一个对象）就是**线程安全**的，这样你就可以在并发应用中使用该代码而不会出现任何问题。

## 不可变对象

**不可变对象**是一个具有非常特殊特性的对象。在初始化后，你不能修改它的可见状态（属性的值）。如果你想修改一个不可变对象，你必须创建一个新的对象。

它的主要优点是它是线程安全的。你可以在并发应用中使用它而不会出现任何问题。

不可变对象的一个例子是 Java 中的`String`类。当你给一个`String`对象赋一个新值时，你实际上是创建了一个新的字符串。

## 原子操作和变量

**原子操作**是一种看起来对程序的其他任务瞬间发生的操作。在并发应用中，你可以使用同步机制来实现一个原子操作的整个操作。

**原子变量**是一种具有原子操作来设置和获取其值的变量。你可以使用同步机制来实现原子变量，或者使用不需要任何同步的 CAS 来以无锁的方式实现原子变量。

## 共享内存与消息传递

任务可以使用两种不同的方法来相互通信。第一种是**共享内存**，通常在任务在同一台计算机上运行时使用。任务使用相同的内存区域来写入和读取值。为了避免问题，对这个共享内存的访问必须在由同步机制保护的临界区域内。

另一个同步机制是**消息传递**，通常在任务在不同计算机上运行时使用。当一个任务需要与另一个任务通信时，它发送遵循预定义协议的消息。这种通信可以是同步的，如果发送者被阻塞等待响应，或者是异步的，如果发送者在发送消息后继续执行。

# 并发应用程序中可能出现的问题

编写并发应用程序并不是一件容易的工作。如果您错误地使用同步机制，您的应用程序中的任务可能会出现不同的问题。在本节中，我们描述了其中一些问题。

## 数据竞争

在应用程序中，当有两个或更多任务在没有使用任何同步机制的情况下写入共享变量时，您可能会发生数据竞争（也称为竞争条件）。

在这种情况下，您的应用程序的最终结果可能取决于任务的执行顺序。看下面的例子：

```java
package com.packt.java.concurrency;

public class Account {

  private float balance;

  public void modify (float difference) {

    float value=this.balance;
    this.balance=value+difference;
  }

}
```

想象一下，两个不同的任务在同一个`Account`对象中执行“modify（）”方法。根据任务中句子的执行顺序，最终结果可能会有所不同。假设初始余额为 1000，两个任务都使用 1000 作为参数调用“modify（）”方法。最终结果应该是 3000，但是如果两个任务同时执行第一句，然后同时执行第二句，最终结果将是 2000。正如您所看到的，“modify（）”方法不是原子的，`Account`类也不是线程安全的。

## 死锁

在您的并发应用程序中存在**死锁**，当有两个或更多任务等待必须从其他任务中释放的共享资源时，因此它们都无法获得所需的资源并将被无限期地阻塞。它发生在系统中同时发生四个条件。它们是**Coffman 的条件**，如下所示：

+   互斥排斥：死锁中涉及的资源必须是不可共享的。一次只有一个任务可以使用资源。

+   持有和等待条件：一个任务拥有一个资源的互斥，并且正在请求另一个资源的互斥。在等待时，它不会释放任何资源。

+   不可抢占：资源只能由持有它们的任务释放。

+   循环等待：任务 1 正在等待任务 2 持有的资源，而任务 2 正在等待任务 3 持有的资源，依此类推，直到有任务 n 等待任务 1 持有的资源。

有一些机制可以用来避免死锁：

+   忽略它们：这是最常用的机制。您假设在您的系统上永远不会发生死锁，如果发生了，您可以看到停止应用程序的后果，并不得不重新执行它。

+   检测：系统有一个特殊的任务，分析系统的状态以检测是否发生了死锁。如果它检测到死锁，它可以采取行动来解决问题。例如，完成一个任务或强制释放资源。

+   预防：如果您想要在系统中预防死锁，您必须预防 Coffman 的一个或多个条件。

+   避免：如果您在任务开始执行之前了解使用的资源的信息，可以避免死锁。当任务想要开始执行时，您可以分析系统中空闲的资源以及任务需要的资源，以决定它是否可以开始执行。

## 活锁

当您的系统中有两个任务始终由于对方的操作而改变其状态时，就会发生**活锁**。因此，它们处于状态更改循环中，无法继续。

例如，您有两个任务——任务 1 和任务 2——都需要两个资源：资源 1 和资源 2。假设任务 1 锁定了资源 1，任务 2 锁定了资源 2。由于它们无法获得所需的资源，它们释放资源并重新开始循环。这种情况可能无限期地持续下去，因此任务永远不会结束执行。

## 资源匮乏

**资源饥饿**发生在系统中有一个任务永远无法获得需要继续执行的资源时。当有多个任务等待资源并且资源被释放时，系统必须选择下一个可以使用它的任务。如果你的系统没有一个好的算法，可能会有线程长时间等待资源。

**公平性**是解决这个问题的方法。所有等待资源的任务必须在一定时间内获得资源。一种选择是实现一个算法，考虑任务等待资源的时间，以选择下一个将持有资源的任务。然而，公平实现锁需要额外的开销，可能会降低程序的吞吐量。

## 优先级反转

**优先级反转**发生在低优先级任务持有高优先级任务需要的资源时，因此低优先级任务在高优先级任务之前完成执行。

# 设计并发算法的方法论

在这一部分，我们将提出一个五步方法论，以获得顺序算法的并发版本。这是基于英特尔在其《线程方法论：原理与实践》文档中提出的方法。

## 起点 - 算法的顺序版本

我们实现并发算法的起点将是它的顺序版本。当然，我们可以从头开始设计一个并发算法，但我认为算法的顺序版本会给我们带来两个优势：

+   我们可以使用顺序算法来测试我们的并发算法是否生成正确的结果。当它们接收相同的输入时，两个算法必须生成相同的输出，这样我们可以检测并发版本中的一些问题，比如数据竞争或类似的情况。

+   我们可以测量两种算法的吞吐量，看看并发使用是否真的能在响应时间或算法在一定时间内处理的数据量方面给我们带来真正的改进。

## 第一步 - 分析

在这一步中，我们将分析算法的顺序版本，寻找可以以并行方式执行的代码部分。我们应该特别注意那些大部分时间执行或执行更多代码的部分，因为通过实现这些部分的并发版本，我们将获得更大的性能改进。

这个过程的好候选者是循环，其中一个步骤独立于其他步骤，或者代码的部分独立于代码的其他部分（例如，初始化应用程序的算法，打开与数据库的连接，加载配置文件，初始化一些对象。所有前面的任务彼此独立）。

## 第二步 - 设计

一旦你知道要并行化的代码部分，你必须决定如何进行并行化。

代码的变化将影响应用程序的两个主要部分：

+   代码结构

+   数据结构的组织

你可以采取两种不同的方法来完成这个任务：

+   **任务分解**：当你将代码分割成两个或更多独立的任务可以同时执行时，你进行任务分解。也许其中一些任务必须按照给定的顺序执行，或者必须在同一点等待。你必须使用同步机制来实现这种行为。

+   **数据分解**：当你有多个相同任务的实例，它们使用数据集的一个子集时，你进行数据分解。这个数据集将是一个共享资源，所以如果任务需要修改数据，你必须通过实现临界区来保护对它的访问。

另一个重要的要点是要记住您解决方案的粒度。实现算法的并行版本的目标是实现改进的性能，因此您应该使用所有可用的处理器或核心。另一方面，当您使用同步机制时，您会引入一些必须执行的额外指令。如果您将算法分解为许多小任务（细粒度粒度），同步引入的额外代码可能导致性能下降。如果您将算法分解为少于核心数的任务（粗粒度粒度），则没有充分利用所有资源。此外，您必须考虑每个线程必须执行的工作，特别是如果您实现了细粒度粒度。如果您有一个比其他任务更长的任务，该任务将决定应用程序的执行时间。您必须在这两个点之间找到平衡。

## 第 3 步 - 实现

下一步是使用编程语言和（如果必要）线程库实现并行算法。在本书的示例中，您将使用 Java 来实现所有算法。

## 第 4 步 - 测试

在完成实现后，您必须测试并行算法。如果您有算法的顺序版本，您可以比较两种算法的结果以验证您的并行实现是否正确。

测试和调试并行实现是困难的任务，因为应用程序的不同任务的执行顺序不能保证。在第十一章中，*测试和监视并发应用程序*，您将学习到有效执行这些任务的技巧和工具。

## 第 5 步 - 调优

最后一步是比较并行和顺序算法的吞吐量。如果结果不如预期，您必须检查算法，寻找并行算法性能不佳的原因。

您还可以测试算法的不同参数（例如，粒度或任务数量）以找到最佳配置。

有不同的指标来衡量并行化算法可能获得的性能改进。最流行的三个指标是：

+   **加速比**：这是衡量并行和顺序算法版本之间相对性能改进的指标：![第 5 步 - 调优](img/00002.jpeg)

这里，*T* *[顺序]* 是顺序算法版本的执行时间，*T* *[并发]* 是并行版本的执行时间。

+   **阿姆达尔定律**：这用于计算通过算法并行化获得的最大预期改进：![第 5 步 - 调优](img/00003.jpeg)

这里，*P*是可以并行化的代码的百分比，*N*是您将执行算法的计算机的核心数。

例如，如果您可以并行化 75%的代码并且您有四个核心，最大加速比将由以下公式给出：

![第 5 步 - 调优](img/00004.jpeg)

+   **古斯塔夫森-巴西斯定律**：阿姆达尔定律有一个限制。它假设在增加核心数时，您拥有相同的输入数据集，但通常，当您拥有更多核心时，您希望处理更多数据。古斯塔夫森定律提出，当您有更多可用的核心时，可以使用以下公式在相同时间内解决更大的问题：![第 5 步 - 调优](img/00005.jpeg)

这里，*N*是核心数，*P*是可并行化代码的百分比。

如果我们使用与之前相同的示例，由古斯塔夫森定律计算得出的加速比为：

![第 5 步 - 调优](img/00006.jpeg)

## 结论

在这一部分，您学习了在想要并行化顺序算法时必须考虑的一些重要问题。

首先，不是每个算法都可以并行化。例如，如果你必须执行一个循环，其中迭代的结果取决于前一次迭代的结果，那么你无法并行化该循环。递归算法是另一个例子，由于类似的原因可以并行化。

另一个重要的事情是，性能更好的顺序算法的顺序版本可能不是并行化的一个好的起点。如果你开始并行化一个算法，并且发现自己陷入困境，因为你不容易找到代码的独立部分，你必须寻找算法的其他版本，并验证该版本是否可以更容易地并行化。

最后，当你实现一个并发应用程序（从头开始或基于顺序算法），你必须考虑以下几点：

+   **效率**：并行算法必须在比顺序算法更短的时间内结束。并行化算法的第一个目标是其运行时间比顺序算法短，或者它可以在相同的时间内处理更多的数据。

+   **简单性**：当你实现一个算法（并行或非并行）时，你必须尽量保持简单。这样更容易实现、测试、调试和维护，而且错误更少。

+   **可移植性**：你的并行算法应该在不同的平台上执行，只需进行最小的更改。在本书中你将使用 Java，这一点将非常容易。使用 Java，你可以在每个操作系统上执行你的程序，而不需要任何更改（如果你按照必须的方式实现程序）。

+   **可扩展性**：如果增加核心的数量，你的算法会发生什么？如前所述，你应该使用所有可用的核心，因此你的算法应该准备利用所有可用的资源。

# Java 并发 API

Java 编程语言拥有非常丰富的并发 API。它包含了管理并发的基本元素的类，如`Thread`、`Lock`和`Semaphore`，以及实现非常高级的同步机制的类，如**执行器框架**或新的并行`Stream`API。

在本节中，我们将介绍构成并发 API 的基本类。

## 基本的并发类

Java 并发 API 的基本类包括：

+   `Thread`类：这个类代表执行并发 Java 应用程序的所有线程

+   `Runnable`接口：这是在 Java 中创建并发应用程序的另一种方式

+   `ThreadLocal`类：这是一个用于在线程本地存储变量的类

+   `ThreadFactory`接口：这是你可以用来创建自定义线程的工厂设计模式的基础

## 同步机制

Java 并发 API 包括不同的同步机制，允许你：

+   定义访问共享资源的临界区

+   在一个共同点同步不同的任务

以下机制被认为是最重要的同步机制：

+   `synchronized`关键字：`synchronized`关键字允许你在代码块或整个方法中定义临界区。

+   `Lock`接口：`Lock`提供了比`synchronized`关键字更灵活的同步操作。有不同种类的锁：`ReentrantLock`，用于实现可以与条件关联的锁；`ReentrantReadWriteLock`，用于分离读写操作；以及`StampedLock`，这是 Java 8 的一个新特性，包括三种模式来控制读/写访问。

+   `Semaphore`类：实现经典信号量以实现同步的类。Java 支持二进制和一般信号量。

+   `CountDownLatch`类：允许任务等待多个操作的完成。

+   `CyclicBarrier`类：允许多个线程在一个共同点同步的类。

+   `Phaser`类：一个允许你控制分阶段执行任务的类。在所有任务完成当前阶段之前，没有一个任务会进入下一个阶段。

## 执行器

执行器框架是一种允许你分离线程创建和管理以实现并发任务的机制。你不必担心线程的创建和管理，只需要创建任务并将它们发送到执行器。参与该框架的主要类有：

+   `Executor`和`ExecutorService`接口：它们包括所有执行器的常用方法。

+   `ThreadPoolExecutor`：这是一个允许你获取一个具有线程池的执行器，并可选择定义最大并行任务数的类

+   `ScheduledThreadPoolExecutor`：这是一种特殊类型的执行器，允许你在延迟后或定期执行任务

+   `Executors`：这是一个简化执行器创建的类

+   `Callable`接口：这是*Runnable*接口的一种替代方式，它是一个可以返回值的独立任务

+   `Future`接口：这是一个包括获取`Callable`接口返回值和控制其状态的方法的接口

## Fork/Join 框架

**Fork/Join 框架**定义了一种特殊类型的执行器，专门用于使用分而治之技术解决问题。它包括一种机制来优化解决这类问题的并发任务的执行。Fork/Join 特别适用于细粒度的并行性，因为它在将新任务放入队列和执行排队任务方面的开销非常低。参与该框架的主要类和接口有：

+   `ForkJoinPool`：这是一个实现将运行任务的执行器的类

+   `ForkJoinTask`：这是一个可以在`ForkJoinPool`类中执行的任务

+   `ForkJoinWorkerThread`：这是一个将在`ForkJoinPool`类中执行任务的线程

## 并行流

**流**和**Lambda 表达式**可能是 Java 8 版本中最重要的两个新特性。流已经作为`Collection`接口和其他数据源的一个方法添加，允许处理数据结构的所有元素，生成新的结构，过滤数据，并使用映射和减少技术实现算法。

一种特殊类型的流是并行流，它以并行方式实现其操作。使用并行流涉及的最重要的元素有：

+   `Stream`接口：这是一个定义你可以在流上执行的所有操作的接口。

+   `Optional`：这是一个可能包含非空值的容器对象。

+   `Collectors`：这是一个实现减少操作的类，可以作为流操作序列的一部分使用。

+   Lambda 表达式：流被设计为与 Lambda 表达式一起工作。大多数流方法接受 Lambda 表达式作为参数。这允许你实现更紧凑的操作版本。

## 并发数据结构

Java API 的普通数据结构（`ArrayList`，`Hashtable`等）在并发应用中不适合工作，除非你使用外部同步机制。如果你使用它，将会为你的应用程序增加大量的额外计算时间。如果你不使用它，你的应用程序可能会出现竞争条件。如果你从多个线程修改它们并发生竞争条件，可能会出现各种异常抛出（如`ConcurrentModificationException`和`ArrayIndexOutOfBoundsException`），可能会出现静默数据丢失，或者你的程序甚至可能会陷入无限循环。

Java 并发 API 包括许多可以在并发应用中使用而不会有风险的数据结构。我们可以将它们分类为两组：

+   **阻塞数据结构**：这些包括在数据结构为空并且您想要获取一个值时，阻止调用任务的方法。

+   **非阻塞数据结构**：如果操作可以立即完成，它不会阻止调用任务。否则，它会返回`null`值或抛出异常。

以下是一些数据结构：

+   `ConcurrentLinkedDeque`：这是一个非阻塞列表

+   `ConcurrentLinkedQueue`：这是一个非阻塞队列

+   `LinkedBlockingDeque`：这是一个阻塞列表

+   `LinkedBlockingQueue`：这是一个阻塞队列

+   `PriorityBlockingQueue`：这是一个根据优先级排序其元素的阻塞队列

+   `ConcurrentSkipListMap`：这是一个非阻塞可导航映射

+   `ConcurrentHashMap`：这是一个非阻塞哈希映射

+   `AtomicBoolean`、`AtomicInteger`、`AtomicLong`和`AtomicReference`：这些是基本 Java 数据类型的原子实现

# 并发设计模式

在软件工程中，**设计模式**是对一个常见问题的解决方案。这个解决方案已经被多次使用，并且已经被证明是解决问题的最佳方案。您可以使用它们来避免每次解决这些问题时都要“重新发明轮子”。**单例**或**工厂**是几乎每个应用程序中使用的常见设计模式的例子。

并发性也有自己的设计模式。在本节中，我们描述了一些最有用的并发设计模式及其在 Java 语言中的实现。

## 信号

这个设计模式解释了如何实现一个任务必须通知另一个任务的事件的情况。实现这个模式的最简单方法是使用 Java 语言的`ReentrantLock`或`Semaphore`类，甚至是`Object`类中包含的`wait()`和`notify()`方法。

看下面的例子：

```java
public void task1() {
  section1();
  commonObject.notify();
}

public void task2() {
  commonObject.wait();
  section2();
}
```

在这些情况下，`section2()`方法将始终在`section1()`方法之后执行。

## 会合

这个设计模式是**信号**模式的一般化。在这种情况下，第一个任务等待第二个任务的事件，第二个任务等待第一个任务的事件。解决方案类似于信号，但在这种情况下，您必须使用两个对象而不是一个。

看下面的例子：

```java
public void task1() {
  section1_1();
  commonObject1.notify();
  commonObject2.wait();
  section1_2();
}
public void task2() {
  section2_1();
  commonObject2.notify();
  commonObject1.wait();
  section2_2();
}
```

在这些情况下，`section2_2()`总是在`section1_1()`之后执行，`section1_2()`在`section2_1()`之后执行，要注意的是，如果在调用`notify()`方法之前调用`wait()`方法，会导致死锁。

## 互斥

互斥是一种机制，您可以使用它来实现临界区，确保互斥。也就是说，一次只有一个任务可以执行由互斥保护的代码部分。在 Java 中，您可以使用`synchronized`关键字（允许您保护代码部分或整个方法）、`ReentrantLock`类或`Semaphore`类来实现临界区。

看下面的例子：

```java
public void task() {
  preCriticalSection();
  lockObject.lock() // The critical section begins
  criticalSection();
  lockObject.unlock(); // The critical section ends
  postCriticalSection();
}
```

## 多路复用

**多路复用设计模式**是互斥的一般化。在这种情况下，确定数量的任务可以同时执行临界区。例如，当您有多个资源的副本时，这是有用的。在 Java 中实现这个设计模式的最简单方法是使用初始化为可以同时执行临界区的任务数量的`Semaphore`类。

看下面的例子：

```java
public void task() {
  preCriticalSection();
  semaphoreObject.acquire();
  criticalSection();
  semaphoreObject.release();
  postCriticalSection();
}
```

## 屏障

这个设计模式解释了如何实现需要在一个共同点同步一些任务的情况。在所有任务到达同步点之前，没有一个任务可以继续执行。Java 并发 API 提供了`CyclicBarrier`类，这是这个设计模式的一个实现。

看下面的例子：

```java
public void task() {
  preSyncPoint();
  barrierObject.await();
  postSyncPoint();
}
```

## 双重检查锁定

这种设计模式提供了解决在获取锁并检查条件时发生的问题的方法。如果条件为假，您理想情况下已经获得了锁的开销。这种情况的一个例子是对象的延迟初始化。如果您有一个实现`Singleton`设计模式的类，可能会有类似以下的代码：

```java
public class Singleton{
  private static Singleton reference;
  private static final Lock lock=new ReentrantLock();
  public static Singleton getReference() {
    lock.lock();
    try {
        if (reference==null) {
          reference=new Object();
        }
    } finally {
        lock.unlock();
    }
    return reference;
  }
}
```

一个可能的解决方案是在条件中包含锁：

```java
public class Singleton{
  private Object reference;
  private Lock lock=new ReentrantLock();
  public Object getReference() {
    if (reference==null) {
      lock.lock();
      try {
          if (reference == null) {
            reference=new Object();
          }
      } finally {
          lock.unlock();
      }
    }
    return reference;
  }
}
```

这种解决方案仍然存在问题。如果两个任务同时检查条件，将创建两个对象。解决此问题的最佳方法不使用任何显式同步机制：

```java
public class Singleton {

  private static class LazySingleton {
    private static final Singleton INSTANCE = new Singleton();
  }

  public static Singleton getSingleton() {
    return LazySingleton.INSTANCE;
  }

}
```

## 读写锁

当您使用锁来保护对共享变量的访问时，只有一个任务可以访问该变量，无论您要对其执行什么操作。有时，您会有一些您多次修改但多次读取的变量。在这种情况下，锁提供了较差的性能，因为所有读取操作都可以并发进行而不会出现任何问题。为解决这个问题，存在读写锁设计模式。该模式定义了一种特殊类型的锁，具有两个内部锁：一个用于读操作，另一个用于写操作。该锁的行为如下：

+   如果一个任务正在执行读操作，另一个任务想要执行另一个读操作，它可以执行。

+   如果一个任务正在执行读操作，另一个任务想要执行写操作，它将被阻塞，直到所有读取操作完成。

+   如果一个任务正在执行写操作，另一个任务想要执行操作（读或写），它将被阻塞，直到写操作完成。

Java 并发 API 包括实现此设计模式的`ReentrantReadWriteLock`类。如果要从头开始实现此模式，必须非常小心读任务和写任务之间的优先级。如果存在太多的读任务，写任务可能会等待太久。

## 线程池

这种设计模式试图消除为要执行的任务创建线程引入的开销。它由一组线程和要执行的任务队列组成。线程组通常具有固定大小。当线程接近执行任务时，它不会完成执行；它会查找队列中的另一个任务。如果有另一个任务，它会执行它。如果没有，线程将等待，直到队列中插入任务，但不会被销毁。

Java 并发 API 包括一些实现`ExecutorService`接口的类，它们在内部使用线程池。

## 线程本地存储

这种设计模式定义了如何在任务中本地使用全局或静态变量。当类中有静态属性时，类的所有对象都访问属性的相同实例。如果使用线程本地存储，每个线程访问变量的不同实例。

Java 并发 API 包括`ThreadLocal`类来实现此设计模式。

# Java 内存模型

当您在具有多个核心或处理器的计算机上执行并发应用程序时，可能会遇到内存缓存的问题。它们非常有用，可以增加应用程序的性能，但可能会导致数据不一致。当一个任务修改变量的值时，它在缓存中被修改，但在主内存中并没有立即修改。如果另一个任务在变量更新到主内存之前读取该变量的值，它将读取变量的旧值。

并发应用程序可能存在的其他问题是编译器和代码优化器引入的优化。有时，它们重新排列指令以获得更好的性能。在顺序应用程序中，这不会造成任何问题，但在并发应用程序中可能会导致意外结果。

为了解决这样的问题，编程语言引入了内存模型。内存模型描述了个别任务如何通过内存相互交互，以及一个任务所做的更改何时对另一个任务可见。它还定义了允许的代码优化以及在什么情况下允许。

有不同的内存模型。其中一些非常严格（所有任务始终可以访问相同的值），而其他一些不那么严格（只有一些指令更新主内存中的值）。内存模型必须为编译器和优化器开发人员所知，并且对其他程序员是透明的。

Java 是第一种定义自己内存模型的编程语言。JVM 中最初定义的内存模型存在一些问题，并在 Java 5 中重新定义。该内存模型在 Java 8 中是相同的。它在 JSR 133 中定义。基本上，Java 内存模型定义如下：

+   它定义了 volatile、synchronized 和 final 关键字的行为。

+   它确保一个正确同步的并发程序在所有架构上都能正确运行。

+   它创建了**volatile read**，**volatile write**，**lock**和**unlock**指令的部分排序，称为**happens-before**。任务同步也帮助我们建立 happens-before 关系。如果一个动作 happens-before 另一个动作，那么第一个动作对第二个动作是可见的并且有序的。

+   当任务获取监视器时，内存缓存被作废。

+   当任务释放监视器时，缓存数据被刷新到主内存中。

+   对于 Java 程序员来说是透明的。

Java 内存模型的主要目标是，正确编写的并发应用程序将在每个**Java 虚拟机**（**JVM**）上都正确运行，而不受操作系统、CPU 架构和 CPU 核心数量的影响。

# 设计并发算法的技巧和窍门

在这一部分，我们总结了一些设计良好的并发应用程序时必须牢记的技巧和窍门。

## 确定正确的独立任务

您只能执行彼此独立的并发任务。如果您有两个或更多具有顺序依赖性的任务，也许您对尝试并发执行它们并包括同步机制以保证执行顺序没有兴趣。任务将以顺序方式执行，并且您将不得不克服同步机制。另一种情况是当您有一个具有一些先决条件的任务，但这些先决条件彼此独立。在这种情况下，您可以并发执行先决条件，然后使用同步类来控制在所有先决条件完成后执行任务。

另一个不能使用并发的情况是当您有一个循环，并且所有步骤使用前一步生成的数据，或者有一些状态信息从一步到下一步。

## 在尽可能高的级别实现并发

丰富的线程 API，如 Java 并发 API，为您提供了不同的类来在应用程序中实现并发。在 Java 的情况下，您可以使用`Thread`或`Lock`类来控制线程的创建和同步，但它还为您提供了高级并发对象，如执行器或 Fork/Join 框架，允许您执行并发任务。这种高级机制为您带来以下好处：

+   您不必担心线程的创建和管理。您只需创建任务并将它们发送执行。Java 并发 API 控制线程的创建和管理。

+   它们被优化以比直接使用线程提供更好的性能。例如，它们使用线程池来重用线程并避免为每个任务创建线程。您可以从头开始实现这些机制，但这将花费您很多时间，而且这将是一个复杂的任务。

+   它们包括使 API 更加强大的高级功能。例如，在 Java 中，您可以使用执行器执行返回`Future`对象形式的结果的任务。同样，您可以从头开始实现这些机制，但这是不建议的。

+   您的应用程序将更容易从一个操作系统迁移到另一个操作系统，并且它将更具可伸缩性。

+   您的应用程序可能会在未来的 Java 版本中变得更快。Java 开发人员不断改进内部，JVM 优化可能更适合 JDK API。

总之，出于性能和开发时间的原因，在实现并发算法之前，分析线程 API 提供的高级机制。

## 考虑可伸缩性

实现并发算法的主要目标之一是充分利用计算机的所有资源，特别是处理器或核心的数量。但是这个数量可能随时间而变化。硬件不断发展，每年成本都在降低。

当您使用数据分解设计并发算法时，不要假设应用程序将在多少核心或处理器上执行。动态获取系统信息（例如，在 Java 中，您可以使用`Runtime.getRuntime().availableProcessors()`方法获取），并使您的算法使用该信息来计算它将要执行的任务数量。这个过程会增加算法的执行时间，但您的算法将更具可伸缩性。

如果您使用任务分解设计并发算法，情况可能会更加困难。您取决于算法中独立任务的数量，强制增加任务数量将增加同步机制引入的开销，并且应用程序的全局性能甚至可能更差。详细分析算法，以确定是否可以具有动态任务数量。

## 使用线程安全的 API

如果您需要在并发应用程序中使用 Java 库，请先阅读其文档，了解它是否是线程安全的。如果它是线程安全的，您可以在应用程序中使用它而不会出现任何问题。如果不是，您有以下两个选择：

+   如果存在线程安全的替代方案，您应该使用它

+   如果不存在线程安全的替代方案，您应该添加必要的同步以避免所有可能的问题情况，特别是数据竞争条件

例如，如果您需要在并发应用程序中使用 List，如果您将从多个线程更新它，就不应该使用`ArrayList`类，因为它不是线程安全的。在这种情况下，您可以使用`ConcurrentLinkedDeque, CopyOnWriteArrayList`或`LinkedBlockingDeque`等线程安全类。如果您想要使用的类不是线程安全的，首先必须寻找线程安全的替代方案。可能，与您可以实现的任何替代方案相比，使用并发更加优化。

## 永远不要假设执行顺序

在不使用任何同步机制的并发应用程序中执行任务是不确定的。任务的执行顺序以及处理器在执行每个任务之前的时间由操作系统的调度程序确定。它不在乎您是否观察到执行顺序在多次执行中是相同的。下一次可能会有所不同。

这种假设的结果过去常常是数据竞争问题。您的算法的最终结果取决于任务的执行顺序。有时，结果可能是正确的，但其他时候可能是错误的。很难检测数据竞争条件的原因，因此您必须小心不要忘记所有必要的同步元素。
